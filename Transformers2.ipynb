{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-19T16:14:03.374387200Z",
     "start_time": "2023-10-19T16:14:02.996043500Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ortho_group\n",
    "from embedding.schema import Schema\n",
    "from embedding.encoder import Encoder\n",
    "from embedding.structure import Struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "schema = Schema(labels=['A1','A2', 'A3', 'next', 'a','b','c','d','e'], attributes=['A1', 'A2', 'A3', 'next'])\n",
    "\n",
    "n_emb = 1024\n",
    "encoder = Encoder(schema, dim=n_emb)\n",
    "E = encoder.token_emb\n",
    "p_dim = 16\n",
    "Z = ortho_group.rvs(p_dim) # positional embedding operator\n",
    "A_next = encoder.attr_emb[schema.attr_to_ind['next']]    \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T16:14:05.928686Z",
     "start_time": "2023-10-19T16:14:03.376387500Z"
    }
   },
   "id": "c8e4405f0a8066b8"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "def attention_impl(seq, q, k, v, temp=100):\n",
    "    \"\"\"Causal attention over a sequence of vectors.\"\"\"\n",
    "\n",
    "    out = [np.zeros_like(v[0])]*len(seq)\n",
    "    \n",
    "    for i, s in enumerate(seq):\n",
    "        res = np.zeros((i,))\n",
    "        for j, ss in enumerate(seq[:i]):\n",
    "            res[j] = q[i].T @ k[j]\n",
    "            \n",
    "        res *= temp\n",
    "        w = np.exp(res)/np.sum(np.exp(res))\n",
    "        if i != 0:\n",
    "            out[i] = np.sum([w[j]*v[j] for j in range(i)], axis=0)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "\n",
    "def ff_decode(x, C=100):\n",
    "    \"\"\"Feed forward decoder layer\"\"\"\n",
    "    I = np.ones(E.shape[0])\n",
    "    cond = C*(E @ x - .5 * I)\n",
    "    return E.T@(relu(cond + I) - relu(cond))\n",
    "\n",
    "\n",
    "def ff_path_decode(x, p, C=100):\n",
    "    \"\"\"Feed forward path decoder layer\"\"\"\n",
    "    n_attr = encoder.attr_emb.shape[0]\n",
    "    I = np.ones(n_attr)\n",
    "    E_attr = E[:n_attr]\n",
    "    cond = C*(E_attr @ p - .5 * I).repeat(n_emb).reshape(n_attr, n_emb)\n",
    "    trans = np.array([encoder.attr_emb[i].T@x for i in range(n_attr)])\n",
    "\n",
    "    return x + np.sum(relu(cond + trans - x) - relu(cond), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "def attention(seq):\n",
    "    q = [Z.T@s[0] for s in seq]\n",
    "    k = [s[0] for s in seq]\n",
    "    v1 = [s[2] for s in seq]\n",
    "    v2 = [A_next.T@s[3] for s in seq]\n",
    "    a1 = attention_impl(seq, q, k, v1)\n",
    "    a2 = attention_impl(seq, q, k, v2)\n",
    "\n",
    "    return [[0, aa1, 0, aa2, 0] for aa1, aa2 in zip(a1, a2)]\n",
    "\n",
    "def ff1(seq):\n",
    "    res = []\n",
    "    for s in seq:\n",
    "        res.append([0, 0, ff_path_decode(s[1], s[3]) - s[2], 0, 0])\n",
    "    return res\n",
    "\n",
    "def ff2(seq):\n",
    "    res = []\n",
    "    for s in seq:\n",
    "        res.append([0, -s[1], 0, 0, ff_decode(s[2])])\n",
    "    return res\n",
    "\n",
    "def add(s1, s2):\n",
    "    res = []\n",
    "    for ss1, ss2 in zip(s1, s2):\n",
    "        res.append([ss1[i] + ss2[i] for i in range(len(ss1))])\n",
    "    return res\n",
    "\n",
    "\n",
    "def transformer(seq):\n",
    "    x = seq\n",
    "    for _ in range(len(seq)):\n",
    "        x = add(x, ff1(x))\n",
    "        x = add(x, ff2(x))\n",
    "        x = add(x, attention(x))\n",
    "    return x\n",
    "\n",
    "def encode_path(path):\n",
    "    return sum([np.linalg.matrix_power(A_next, i+1) @ E[schema.token_to_ind[p]] for i, p in enumerate(path)])\n",
    "\n",
    "def init_seq(path, v):\n",
    "    ## Initialize seq with positional embedding\n",
    "    p = np.random.normal(size=p_dim)\n",
    "    p /= np.linalg.norm(p)\n",
    "    n_seq = len(path) + 1\n",
    "    seq = []\n",
    "    for i in range(n_seq):\n",
    "        seq.append([p,  # position \n",
    "                    np.zeros(n_emb), # vector\n",
    "                    np.zeros(n_emb), # transformed vector\n",
    "                    np.zeros(n_emb), # path\n",
    "                    np.zeros(n_emb)  # token\n",
    "                    ])\n",
    "        p = Z @ p\n",
    "\n",
    "    # Initialize with encoded vector\n",
    "    seq[0][1] = v\n",
    "\n",
    "    # Encode and initialize path\n",
    "    seq[0][3] = encode_path(path)\n",
    "    \n",
    "    return seq"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T16:14:05.950837600Z",
     "start_time": "2023-10-19T16:14:05.937686400Z"
    }
   },
   "id": "efa868f9061a891"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"a\", \"b\", \"c\", \"a\", \"b\"]\n",
      "[\"a\", \"b\", \"c\", \"d\", \"e\"]\n"
     ]
    }
   ],
   "source": [
    "x = Struct.create(schema, ('a', {'A1': \n",
    "                                     ('b', {'A2': \n",
    "                                                ('c', {'A1': \n",
    "                                                           ('d', {'A3':'e'}),\n",
    "                                                       'A2':\n",
    "                                                           ('a', {'A1':'b'})\n",
    "                                                       }\n",
    "                                                 )}\n",
    "                                      )}\n",
    "                           ))\n",
    "v = encoder.encode(x)\n",
    "\n",
    "path1 = ['A1', 'A2', 'A2', 'A1']\n",
    "path2 = ['A1', 'A2', 'A1', 'A3']\n",
    "\n",
    "x = transformer(init_seq(path1, v))\n",
    "out = [encoder.decode(s[4]) for s in x]\n",
    "print([(o.to_strings()) if o else None for o in out])\n",
    "\n",
    "x = transformer(init_seq(path2, v))\n",
    "out = [encoder.decode(s[4]) for s in x]\n",
    "print([(o.to_strings()) if o else None for o in out])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T16:14:06.189099400Z",
     "start_time": "2023-10-19T16:14:05.946658900Z"
    }
   },
   "id": "c1285221605d475e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
